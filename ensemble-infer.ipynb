{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os, gc, math, json, time, random, collections, sys\nimport multiprocessing as mp\nos.environ['TOKENIZERS_PARALLELISM'] = 'false'\ngc.enable()\n\nfrom string import punctuation\nimport numpy as np\nimport pandas as pd\nfrom tqdm import tqdm\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader, SequentialSampler\n\nfrom transformers import AdamW,AutoConfig, AutoTokenizer,AutoModelForQuestionAnswering, TrainingArguments, Trainer","metadata":{"execution":{"iopub.status.busy":"2021-11-13T22:26:18.454562Z","iopub.execute_input":"2021-11-13T22:26:18.454933Z","iopub.status.idle":"2021-11-13T22:26:18.463223Z","shell.execute_reply.started":"2021-11-13T22:26:18.454890Z","shell.execute_reply":"2021-11-13T22:26:18.462527Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"MAX_SEQ_LENGTH = 400\nDOC_STRIDE = 135\nEVAL_BATCH_SIZE = 128","metadata":{"execution":{"iopub.status.busy":"2021-11-13T22:26:18.464862Z","iopub.execute_input":"2021-11-13T22:26:18.465454Z","iopub.status.idle":"2021-11-13T22:26:18.474913Z","shell.execute_reply.started":"2021-11-13T22:26:18.465415Z","shell.execute_reply":"2021-11-13T22:26:18.474125Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def create_features(example, tokenizer):\n    example[\"question\"] = example[\"question\"].lstrip()\n    \n    tokenized = tokenizer(\n        example[\"question\"],\n        example[\"context\"],\n        truncation=\"only_second\",\n        max_length=MAX_SEQ_LENGTH,\n        stride=DOC_STRIDE,\n        return_overflowing_tokens=True,\n        return_offsets_mapping=True,\n        padding=\"max_length\",\n    )\n\n    features = []\n    for i in range(len(tokenized[\"input_ids\"])):\n        features.append(\n            {\n                \"example_id\": example['id'],\n                'context': example['context'],\n                'question': example['question'],\n                'input_ids': tokenized['input_ids'][i],\n                'attention_mask': tokenized['attention_mask'][i],\n                'offset_mapping': tokenized['offset_mapping'][i],\n                'sequence_ids': [0 if i is None else i for i in tokenized.sequence_ids(i)]\n            }\n        )\n    return features\n","metadata":{"execution":{"iopub.status.busy":"2021-11-13T22:26:18.475922Z","iopub.execute_input":"2021-11-13T22:26:18.478276Z","iopub.status.idle":"2021-11-13T22:26:18.487273Z","shell.execute_reply.started":"2021-11-13T22:26:18.478236Z","shell.execute_reply":"2021-11-13T22:26:18.486384Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class DataTransformer(Dataset):\n    def __init__(self, data):\n        super(DataTransformer, self).__init__()\n        self.data = data\n        \n    def __len__(self):\n        return len(self.data)\n    \n    def __getitem__(self, item):   \n        feature = self.data[item]\n        return {\n            'input_ids':torch.tensor(feature['input_ids'], dtype=torch.long),\n            'attention_mask':torch.tensor(feature['attention_mask'], dtype=torch.long),\n            'offset_mapping':feature['offset_mapping'],\n            'sequence_ids':feature['sequence_ids'],\n            'id':feature['example_id'],\n            'context': feature['context'],\n            'question': feature['question']\n        }","metadata":{"execution":{"iopub.status.busy":"2021-11-13T22:26:18.489506Z","iopub.execute_input":"2021-11-13T22:26:18.489787Z","iopub.status.idle":"2021-11-13T22:26:18.501682Z","shell.execute_reply.started":"2021-11-13T22:26:18.489749Z","shell.execute_reply":"2021-11-13T22:26:18.500818Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def tokenize_after_split(s):\n    return ' '.join(s.split())\n\ntest = pd.read_csv('../input/chaii-hindi-and-tamil-question-answering/test.csv')\n\ntest['context'] = test['context'].apply(tokenize_after_split)\ntest['question'] = test['question'].apply(tokenize_after_split)\ntokenizer = AutoTokenizer.from_pretrained('../input/renew-2')\n\ntest_features = []\nfor i, row in test.iterrows():\n    test_features += create_features(row, tokenizer)\n\ntest_dataset = DataTransformer(test_features)\ntest_dataloader = DataLoader(\n    test_dataset,\n    batch_size=EVAL_BATCH_SIZE, \n    sampler=SequentialSampler(test_dataset),\n    num_workers=2,\n    pin_memory=True\n)","metadata":{"execution":{"iopub.status.busy":"2021-11-13T22:26:18.502958Z","iopub.execute_input":"2021-11-13T22:26:18.504251Z","iopub.status.idle":"2021-11-13T22:26:20.049891Z","shell.execute_reply.started":"2021-11-13T22:26:18.504189Z","shell.execute_reply":"2021-11-13T22:26:20.049100Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_pred(checkpoint_path):\n    \n    model = AutoModelForQuestionAnswering.from_pretrained('../input/renew-2')\n    config = AutoConfig.from_pretrained('../input/renew-2')\n    tokenizer = AutoTokenizer.from_pretrained('../input/renew-2')\n    \n    model.to('cuda')\n    model.load_state_dict(torch.load(checkpoint_path))\n    \n    start_logits, end_logits = [], []\n    for batch in test_dataloader:\n        with torch.no_grad():\n            outputs = model(batch['input_ids'].cuda(), batch['attention_mask'].cuda())\n            outputs_start, outputs_end = outputs.start_logits, outputs.end_logits\n            start_logits.append(outputs_start.cpu().numpy().tolist())\n            end_logits.append(outputs_end.cpu().numpy().tolist())\n            del outputs_start, outputs_end\n    del model, tokenizer, config\n    gc.collect()\n    return np.vstack(start_logits), np.vstack(end_logits)","metadata":{"execution":{"iopub.status.busy":"2021-11-13T22:26:20.051147Z","iopub.execute_input":"2021-11-13T22:26:20.051519Z","iopub.status.idle":"2021-11-13T22:26:20.059634Z","shell.execute_reply.started":"2021-11-13T22:26:20.051477Z","shell.execute_reply":"2021-11-13T22:26:20.058750Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"start_logits_list, end_logits_list = [], []\nnum_models = 3\nfor i in range(num_models):\n    s, e = get_pred(f'../input/renew-{2*(i+1)}/pytorch_model.bin')\n    start_logits_list.append(s)\n    end_logits_list.append(e)\n\nstart_logits, end_logits = 0, 0\n\nfor i in range(num_models):\n    start_logits += start_logits_list[i]\n    end_logits += end_logits_list[i]\n\nstart_logits /= num_models\nend_logits /= num_models","metadata":{"execution":{"iopub.status.busy":"2021-11-13T22:26:20.061074Z","iopub.execute_input":"2021-11-13T22:26:20.061604Z","iopub.status.idle":"2021-11-13T22:27:58.495641Z","shell.execute_reply.started":"2021-11-13T22:26:20.061562Z","shell.execute_reply":"2021-11-13T22:27:58.491121Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def post_process(egs, features, raw_pred):\n    s_logits, e_logits = raw_pred\n    \n    id_to_idx = {}    \n    for i, k in enumerate(egs[\"id\"]):\n        id_to_idx[k] = i\n    \n    f_per_ex = collections.defaultdict(list)\n    for i, feature in enumerate(features):\n        f_per_ex[id_to_idx[feature[\"example_id\"]]].append(i)\n\n    preds = collections.OrderedDict()\n    \n    for i, example in egs.iterrows():\n        okay_ans = []\n        min_score = float('inf')\n        \n        context = example[\"context\"]\n        for feature_idx in f_per_ex[i]:\n\n            start_logits, end_logits, sequence_ids = s_logits[feature_idx], e_logits[feature_idx], features[feature_idx]['sequence_ids']\n            features[feature_idx][\"offset_mapping\"] = [(off if sequence_ids[j] == 1 else None) for j, off in enumerate(features[feature_idx][\"offset_mapping\"])]\n            offset_mapping = features[feature_idx][\"offset_mapping\"]\n            CLS = tokenizer.cls_token_id\n            cls_pos = features[feature_idx][\"input_ids\"].index(CLS)\n            min_score = min(float('inf'), start_logits[cls_pos] + end_logits[cls_pos])\n            start_indices, end_indices = np.argsort(start_logits)[-1 : -21 : -1].tolist(), np.argsort(end_logits)[-1 : -21 : -1].tolist()\n            \n            for start_idx in start_indices:\n                for end_idx in end_indices:\n                    if any([\n                        start_idx >= len(offset_mapping), \n                        end_idx >= len(offset_mapping), \n                        offset_mapping[start_idx] is None, \n                        offset_mapping[end_idx] is None,\n                        end_idx < start_idx,\n                        end_idx - start_idx > 29\n                    ]):\n                        continue\n \n                    answer = {\n                        \"score\": start_logits[start_idx] + end_logits[end_idx],\n                        \"text\": context[offset_mapping[start_idx][0]:offset_mapping[end_idx][1]]\n                    }\n                    okay_ans.append(answer)\n        \n        if len(okay_ans) > 0:\n            best_answer = list(sorted(\n                okay_ans, \n                key=lambda x: x[\"score\"]\n            ))\n            best_answer.reverse()\n            best_answer = best_answer[0]\n        else:\n            best_answer = {\n                \"text\": \"\", \n                \"score\": 0.0\n            }\n        \n        preds[example[\"id\"]] = best_answer[\"text\"]\n        \n        \n    return preds","metadata":{"execution":{"iopub.status.busy":"2021-11-13T22:27:58.502938Z","iopub.execute_input":"2021-11-13T22:27:58.503222Z","iopub.status.idle":"2021-11-13T22:27:58.517869Z","shell.execute_reply.started":"2021-11-13T22:27:58.503166Z","shell.execute_reply":"2021-11-13T22:27:58.517112Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fin_preds = post_process(test, test_features, (start_logits, end_logits))\n\nsubmission = []\nfor p in fin_preds.items():\n    ID, ans = p\n    ans = \" \".join(ans.split())\n    ans = ans.strip(punctuation)\n    submission.append((ID, ans))\n    \ntest_data = pd.merge(\n    left=test,\n    right=pd.DataFrame(submission, columns=[\"id\", \"PredictionString\"]),\n    on='id'\n)\ntest_data[['id', 'PredictionString']].to_csv('submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2021-11-13T22:27:58.519593Z","iopub.execute_input":"2021-11-13T22:27:58.520195Z","iopub.status.idle":"2021-11-13T22:27:58.632727Z","shell.execute_reply.started":"2021-11-13T22:27:58.520158Z","shell.execute_reply":"2021-11-13T22:27:58.631997Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!cat submission.csv","metadata":{"execution":{"iopub.status.busy":"2021-11-13T22:27:58.633757Z","iopub.execute_input":"2021-11-13T22:27:58.635439Z","iopub.status.idle":"2021-11-13T22:27:59.531081Z","shell.execute_reply.started":"2021-11-13T22:27:58.635408Z","shell.execute_reply":"2021-11-13T22:27:59.530239Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}